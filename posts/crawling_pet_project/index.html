<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width">



<link rel="icon" type="image/ico" href="http://localhost:1313//favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313//favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313//favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="http://localhost:1313//android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313//apple-touch-icon.png">

<meta name="description" content="A comprehensive analysis of Korean travel trends in Taiwan through web scraping, text preprocessing, and analysis of Naver blog posts"/>

<title>
    
    Web Scraping and Text Analysis of Travel Trends on Blogs | Data Journal
    
</title>

<link rel="canonical" href="http://localhost:1313/posts/crawling_pet_project/"/>












<link rel="stylesheet" href="/assets/combined.min.a6824bbee0d90d5af09fed9b70395ce7076b615e315037455d903314e96ef91b.css" media="all">





  </head>

  

  
  
  

  <body class="auto">

    <div class="content">
      <header>
        

<div class="header">

    

    <h1 class="header-title">Data Journal</h1>

    <div class="flex">
        

        
        
      
        <p class="small ">
            <a href="/" >
                /Home
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/my-project/" >
                /Portfolio
            </a>
        </p>
        
      
        <p class="small ">
            <a href="/posts/" >
                /Posts
            </a>
        </p>
        
        
    </div>

    

</div>

      </header>

      <main class="main">
        





<div class="breadcrumbs">
    
    <a href="/">Home</a>
    <span class="breadcrumbs-separator"> > </span>
    
    <a href="/posts/">Posts</a>
    <span class="breadcrumbs-separator"> > </span>
    
    <a class="breadcrumbs-current" href="/posts/crawling_pet_project/">Web Scraping and Text Analysis of Travel Trends on Blogs</a>
</div>



<div >

  <div class="single-intro-container">

    

    <h1 class="single-title">Web Scraping and Text Analysis of Travel Trends on Blogs</h1>
    
    <p class="single-summary">A data-driven exploration of Taiwan travel trends using Naver blog analysis and web scraping.</p>
    

    

    <p class="single-readtime">
      
      
      
      <time datetime="2024-11-12T00:00:00&#43;00:00">November 12, 2024</time>
      

      
      &nbsp; Â· &nbsp;
      5 min read
      
    </p>

  </div>

  

  

  

  

  <div class="single-content">
    <h2 id="objective">Objective</h2>
<p>This project explores travel trends on Naver blogs through web scraping and text analysis.</p>
<p>Recently, while texting with a friend who had just started exploring AI, I realized that I had no experience in crawling and scraping for data analysis. Although data pre-processing has been my specialty, I often took on data pre-processing roles in team projects and mostly relied on public data and Kaggle for my work. This realization led me to start this project.</p>
<p>I chose to scrape Naver blog posts about &ldquo;Taiwan Travel&rdquo; because I&rsquo;m planning a trip to Taipei soon and wanted to understand the trends and popular keywords around this topic. (Naver is a Korean search engine, often referred to as &ldquo;Korean Google.&rdquo;)</p>
<p>This pet project focuses on scraping topic-related blog posts, pre-processing the data, and conducting text analysis. I believe it&rsquo;s valuable to document the objective, troubleshooting process, and analysis results.</p>
<h3 id="technologies-used">Technologies Used</h3>
<ul>
<li>Naver API</li>
<li>Python</li>
<li>Google Colab</li>
<li>Basic text preprocessing techniques</li>
<li>Key methods: TF-IDF, sentiment analysis, topic modeling (LDA), word cloud</li>
</ul>
<p>While I won&rsquo;t explain the code line by line, you can find the complete code in my GitHub repository: <a href="https://github.com/KwonNayeon/medium-post-projects/tree/main">KwonNayeon/medium-post-projects</a>.</p>
<h2 id="web-scraping-with-naver-api">Web Scraping with Naver API</h2>
<h3 id="legal-considerations">Legal Considerations</h3>
<p>Before starting the project, I researched the legality of web crawling. Crawling for commercial purposes is generally not recommended, so it&rsquo;s essential to check each website&rsquo;s specific rules. Even for academic or personal projects, developers must take care to avoid causing server stress.</p>
<p>I initially considered X (formerly Twitter) as a data source, but their API is no longer free, and they banned crawling and scraping in 2023. Ultimately, I chose Naver&rsquo;s platform because they provide an official API upon application, and this aligned with my goal of analyzing Korean travel trends in Taiwan.</p>
<h3 id="crawling-process">Crawling Process</h3>
<p>Following dev-woo&rsquo;s <a href="https://developer-woo.tistory.com/60">&ldquo;Python-based Naver blog crawling tutorial&rdquo;</a>, the process involves:</p>
<ol>
<li>Fetching blog URLs for desired keywords using the Naver API (you need to apply for API access)</li>
<li>Opening URLs through Selenium to retrieve the HTML content</li>
<li>Extracting the title, content, and post date from the HTML</li>
<li>Saving the data to a CSV file</li>
</ol>
<h3 id="troubleshooting-setting-up-selenium-in-colab">Troubleshooting: Setting Up Selenium in Colab</h3>
<p>I encountered issues with mounting the Chrome driver in Colab. Here&rsquo;s the simplified, working setup code:</p>
<div class="highlight"><pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff6ac1">from</span> selenium <span style="color:#ff6ac1">import</span> webdriver
</span></span><span style="display:flex;"><span><span style="color:#ff6ac1">from</span> selenium.webdriver.chrome.options <span style="color:#ff6ac1">import</span> Options
</span></span><span style="display:flex;"><span><span style="color:#ff6ac1">from</span> bs4 <span style="color:#ff6ac1">import</span> BeautifulSoup
</span></span><span style="display:flex;"><span><span style="color:#ff6ac1">import</span> pandas <span style="color:#ff6ac1">as</span> pd
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#78787e">## Chrome options setup</span>
</span></span><span style="display:flex;"><span>chrome_options <span style="color:#ff6ac1">=</span> Options()
</span></span><span style="display:flex;"><span>chrome_options<span style="color:#ff6ac1">.</span>add_argument(<span style="color:#5af78e">&#39;--headless&#39;</span>)
</span></span><span style="display:flex;"><span>chrome_options<span style="color:#ff6ac1">.</span>add_argument(<span style="color:#5af78e">&#39;--no-sandbox&#39;</span>)
</span></span><span style="display:flex;"><span>chrome_options<span style="color:#ff6ac1">.</span>add_argument(<span style="color:#5af78e">&#39;--disable-dev-shm-usage&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#78787e">## Initialize webdriver</span>
</span></span><span style="display:flex;"><span>driver <span style="color:#ff6ac1">=</span> webdriver<span style="color:#ff6ac1">.</span>Chrome(options<span style="color:#ff6ac1">=</span>chrome_options)
</span></span></code></pre></div><p>You can verify the setup with:</p>
<div class="highlight"><pre tabindex="0" style="color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff6ac1">try</span>:
</span></span><span style="display:flex;"><span>    driver<span style="color:#ff6ac1">.</span>get(<span style="color:#5af78e">&#39;https://www.google.com&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#34;Page title:&#34;</span>, driver<span style="color:#ff6ac1">.</span>title)
</span></span><span style="display:flex;"><span>    <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#34;Setup complete!&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#ff6ac1">except</span> Exception <span style="color:#ff6ac1">as</span> e:
</span></span><span style="display:flex;"><span>    <span style="color:#ff5c57">print</span>(<span style="color:#5af78e">&#34;Error:&#34;</span>, e)
</span></span><span style="display:flex;"><span><span style="color:#ff6ac1">finally</span>:
</span></span><span style="display:flex;"><span>    driver<span style="color:#ff6ac1">.</span>quit()
</span></span></code></pre></div><h2 id="text-pre-processing-and-analysis">Text Pre-processing and Analysis</h2>
<h3 id="pre-processing-methodology">Pre-processing Methodology</h3>
<p>I applied several text preprocessing techniques, including HTML tag removal, special character cleaning, case normalization, tokenization, and morphological analysis. Through this process, I learned that selecting appropriate stopwords is crucial regardless of language.</p>
<p>Even after using <a href="https://gist.github.com/spikeekips/40eea22ef4a89f629abd87eed535ac6a">stopwords-ko.txt</a> from spikeekips&rsquo; Gist on GitHub, the crawled data contained unexpected technical terms like <em>&lsquo;pzp&rsquo;, &lsquo;pc&rsquo;, &lsquo;hdp&rsquo;,</em> and <em>&lsquo;hd&rsquo;</em> that required additional cleaning. This experience reinforced that thorough preprocessing is essential for accurate analysis.</p>
<h3 id="text-analysis-results">Text Analysis Results</h3>
<h4 id="keyword-analysis">Keyword Analysis</h4>
<p>The most frequently appearing terms included <em>Taiwan, Taipei, travel, tour, night market, hotel, photo,</em> and <em>people.</em></p>
<h4 id="sentiment-distribution">Sentiment Distribution</h4>
<p>Most posts exhibited positive sentiment, focusing on travel experiences and recommendations. Representative examples included:</p>
<ul>
<li>Neutral: <em>&ldquo;4 nights and 5 days in Taiwan, traveling around and eating nonstopâ¦&rdquo;</em></li>
<li>Positive: <em>&ldquo;A 3-day tour of Taiwan, a free tour around Taipei packed with experiencesâ¦&rdquo;</em></li>
<li>Positive: <em>&ldquo;Visiting the Taipei Fun Pass, with a summary of travel expenses and photosâ¦&rdquo;</em></li>
</ul>
<h4 id="topic-categories">Topic Categories</h4>
<p>The content fell into five main categories:</p>
<ol>
<li><strong>City Tours</strong> â Popular destinations like Jiufen and Shifen</li>
<li><strong>Food &amp; Dining</strong> â Local cuisine and restaurant recommendations</li>
<li><strong>Cultural Sites</strong> â Night markets, National Palace Museum, and historical locations</li>
<li><strong>Travel Tips</strong> â Itinerary planning, tour suggestions, and essential items</li>
<li><strong>Travel Logistics</strong> â Transportation guidance, eSIM information, and accommodation details</li>
</ol>
<h4 id="word-cloud">Word Cloud</h4>
<p>It showed similar keywords to those in other analyses, such as <em>Taiwan, travel, Taipei, hotel, night markets, tours, airport,</em> and <em>photos.</em>











<figure class="">

    <div>
        <img loading="lazy" alt="Taiwan Travel Word Cloud" src=" /images/wordcloud_taiwan.png">
    </div>

    
</figure></p>
<h2 id="key-findings">Key Findings</h2>
<p><strong>From a data analysis perspective,</strong> the results closely matched my expectations. When searching for travel information in Korean, I found a strong emphasis on food, travel tips, must-bring items, and detailed itinerary suggestions. This aligns with the types of content I anticipated encountering.</p>
<p><strong>From a technical perspective,</strong> this project reinforced that text preprocessing is critical for any data analysis. While I performed basic text cleaning for this pet project, I recognized that for larger-scale or corporate projects aimed at deriving meaningful customer insights, comprehensive and accurate data cleaning is a necessity.</p>
<h2 id="future-directions">Future Directions</h2>
<p>Although this is a small-scale project, I believe the experience gained in web scraping, text preprocessing, and text analysis will be invaluable for future projects. If I get the opportunity to work on text analysis again, I plan to explore more advanced techniques for text data visualization and implement more sophisticated text cleaning methods to improve the accuracy and depth of the analysis.</p>
<p>While I didn&rsquo;t delve into explaining the code in detail in this post, you can check out the full code in my GitHub repository: <a href="https://github.com/KwonNayeon/medium-post-projects/tree/main">KwonNayeon/medium-post-projects</a>.</p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://developers.naver.com/main/">Naver Developer API</a> for web scraping</li>
<li><em><a href="https://developer-woo.tistory.com/60">Python-based Naver blog crawling tutorial</a></em> by dev-woo</li>
<li><a href="https://gist.github.com/spikeekips/40eea22ef4a89f629abd87eed535ac6a">stopwords-ko.txt</a> from spikeekips&rsquo; Gist on GitHub</li>
<li><em><a href="https://brunch.co.kr/@8d1b089f514b4d5/33">í©ë²ì ì¼ë¡ &lsquo;ì¹ í¬ë¡¤ë§&rsquo;íë ë°©ë² (ä¸)</a></em> by ì¼ëíê¸°ì¼</li>
</ul>

    
  </div>

  


  

  

  

  
  <div class="back-to-top">
    <a href="#top">
      back to top
    </a>
  </div>
  

</div>


      </main>
    </div>

    <footer>
      

    
    <p>Powered by
        <a href="https://gohugo.io/">Hugo</a>
        and
        <a href="https://github.com/tomfran/typo">tomfran/typo</a>
    </p>
    
    
    



    </footer>
    
  </body>

  <script>

  function isAuto() {
    return document.body.classList.contains("auto");
  }

  function setTheme() {
    if (!isAuto()) {
      return
    }

    document.body.classList.remove("auto");
    let cls = "light";
    if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
      cls = "dark";
    }

    document.body.classList.add(cls);
  }

  function invertBody() {
    document.body.classList.toggle("dark");
    document.body.classList.toggle("light");
  }

  if (isAuto()) {
    window.matchMedia('(prefers-color-scheme: dark)').addListener(invertBody);
  }

  setTheme();

</script>

</html>